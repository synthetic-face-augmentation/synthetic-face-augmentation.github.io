<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">

  <meta property="og:title" content="Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID" />
  <meta property="og:url" content="" />
  <meta property="og:image" content="static/figures/fig1.jpg" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <title>Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <!-- <link rel="icon" href="static/figures/icon2.png"> -->

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true
      },
      TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js"]
      }
    });
  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML'></script>
</head>

<body>


  <section class="publication-header">
    <div class="hero-body">
      <div class="container is-max-widescreen">
        <!-- <div class="columns is-centered"> -->
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID</h1>
        </div>
      </div>
    </div>
  </section>





  <section class="publication-author-block">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div class="is-size-4 publication-authors">
              <span class="author-block"><a href="https://www.linkedin.com/in/korayulusan/" target="_blank">Koray Ulusan</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://scholar.google.com/citations?user=IgH9QkEAAAAJ" target="_blank">Benjamin Kiefer</a><sup>1,2</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Tuebingen</span>
              <span class="author-block"><sup>2</sup>LOOKOUT</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.03557" target="_blank" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2505.03557" target="_blank" class="external-link button is-normal is-rounded">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- <span class="link-block">
                <a href="#" target="_blank"
                class="external-link button is-n  ormal is-rounded">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code (Coming Soon)</span>
              </a>
              </span> -->


              </div>
            </div>


            <div class="is-size-5 publication-authors">
              <span class="author-block">Accepted to <a href="https://syndata4cv.github.io/" target="_blank">SynData4CV <!-- Workshop -->@ CVPR 2025</a></span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <!-- <div class="hero-body"> -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <!-- <div id="results-carousel" class="carousel results-carousel"> -->
          <div class="container">
            <div class="item">
              <!-- Video will be added when available -->
              <!-- <video poster="" id="teaser" autoplay controls muted height="150%">
          <source src="static/figures/face_augmentation_teaser.mp4"
          type="video/mp4">
        </video> -->
              <img src="static/figures/fig1.jpg" width="100%" alt="Face Augmentation Pipeline Overview" />
              <h2 class="content has-text-justified">
                <br>
                Pipeline for generating personalized portraits using synthetic images enhanced through classical and generative augmentations to improve identity resemblance in
                DreamBooth and InstantID outputs. We compare classical augmentations with generative augmentation using InstantID's synthetic images to enrich training data.
              </h2>
            </div>
          </div>
          <!--  </div> -->
        </div>
      </div>
      <!--  </div> -->
    </section>

    <section class="section hero section-contrast">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="item">
              <p style="margin-bottom: 30px">
                <!-- Video will be added when available -->
                <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/figures/sketchy_video.mp4"
          type="video/mp4">
        </video> -->
              </p>
            </div>
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Personalizing Stable Diffusion for professional portrait generation from amateur photos faces challenges in maintaining facial resemblance. This paper evaluates the
                impact of augmentation strategies on two personalization methods: DreamBooth and InstantID.
              </p>
              <p>
                We compare classical augmentations (flipping, cropping, color adjustments) with generative augmentation using InstantID's synthetic images to enrich training data.
                Using SDXL and a new FaceDistance metric based on FaceNet, we quantitatively assess facial similarity.
              </p>
              <p>
                Results show classical augmentations can cause artifacts harming identity retention, while InstantID improves fidelity when balanced with real images to avoid
                overfitting. A user study with 97 participants confirms high photorealism and preferences for InstantID's polished look versus DreamBooth's identity accuracy.
              </p>
              <p>
                Our findings inform effective augmentation strategies for personalized text-to-image generation.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->
      </div>
    </section>

    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title has-text-centered">Augmentation Strategy Results</h2>
              <div class="content has-text-justified">
                <p>
                  We evaluate augmentation strategies on <strong>DreamBooth</strong> and <strong>InstantID</strong> personalization methods using the SDXL model and a new
                  <em>FaceDistance</em> metric to measure facial similarity.
                </p>
                <h3>Key Findings</h3>
                <ul>
                  <li><strong>Classical Augmentations (DreamBooth):</strong> Often introduce artifacts harming identity retention. Techniques like random flips and background
                    replacements can slow training or degrade image quality. Gray backgrounds (especially light gray) work best. Resizing images to ~1MP aligns well with SDXL
                    training, while ESR-GAN upscaling introduces artifacts.</li>
                  <li><strong>Generative Augmentations (InstantID):</strong> Enhance DreamBooth training by producing diverse, realistic synthetic images that improve facial
                    similarity. Maintaining a balance between real and synthetic images is critical to avoid overfitting. Though effective, the 2-step generation method is
                    computationally costly.</li>
                  <li><strong>InstantIDâ€™s Behavior:</strong> Rotational/shape augmentations and background replacements degrade similarity. Upscaling with traditional methods works
                    better than neural upscaling. Using multiple reference images significantly improves consistency. Face replacement offers better pose control and faster
                    generation, but requires well-posed reference photos.</li>
                </ul>
                <h3>Overall Insights</h3>
                <ul>
                  <li>DreamBooth excels in facial similarity, while InstantID yields a more professional, "Photoshopped" look favored by some users.</li>
                  <li>FaceDistance effectively ranks facial similarity but has limited sensitivity for fine distinctions and holistic personalization.</li>
                  <li>Datasets with very few images \((\leq 3)\) can result in poor subject representation despite seeming accurate to outsiders.</li>
                </ul>
              </div>
            </div>
          </div>

          <div id="results-carousel" class="carousel results-carousel">
            <div class="column is-centered has-text-centered">
              <img src="static/figures/fig2.jpg" width="600" alt="Classical Augmentations" />
            </div>
            <div class="column is-centered has-text-centered">
              <img src="static/figures/fig3.jpg" width="600" alt="Generative Augmentations" />
            </div>
            <div class="column is-centered has-text-centered">
              <img src="static/figures/fig4-ab.jpg" width="600" alt="DreamBooth vs InstantID" />
            </div>
            <div class="column is-centered has-text-centered">
              <img src="static/figures/fig4-cd.jpg" width="600" alt="DreamBooth vs InstantID" />
            </div>
            <div class="column is-centered has-text-centered">
              <img src="static/figures/fig10.jpg" width="600" alt="InstantID" />
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero section-contrast">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title has-text-centered">FaceDistance Metric</h2>
              <div class="content has-text-justified">
                <p>
                  To quantify facial similarity in generated images, we employ the <strong>FaceDistance</strong> metric based on FaceNet embeddings <a
                    href="https://arxiv.org/abs/1503.03832" target="_blank" rel="noopener noreferrer">[Schroff et al., 2015]</a>. FaceNet projects facial images into a
                  128-dimensional hyperspherical embedding space where spatial proximity reflects facial similarity.
                </p>

                <p>
                  <strong>Definition:</strong> Given batches of generated images \( G = \{G_i\}_{i=1}^m \) and real images \( R = \{R_j\}_{j=1}^n \), the FaceDistance is defined
                  as:
                </p>

                <div class="has-text-centered" style="margin: 20px 0;">
                  \[
                  \bigl[\operatorname{FaceDistance}(G, R)\bigr]_i := \frac{1}{n} \sum_{j=1}^n \delta^{[0,2]}_{\cos}\bigl(f(G_i), f(R_j)\bigr), \quad i=1, \dots, m
                  \]
                </div>

                <p>where</p>

                <ul>
                  <li>\( f(\cdot) := \operatorname{FaceNet}\bigl(\operatorname{MTCNN}(\cdot)\bigr) \)</li>
                  <li>\(\delta^{[0,2]}_{\cos}(\mathbf{x}, \mathbf{y}) := \operatorname{clip}_{[0,2]} \left( 1 - \frac{\mathbf{x}^\top \mathbf{y}}{\|\mathbf{x}\| \, \|\mathbf{y}\|}
                    \right)\)</li>

                </ul>

                <p>The clipping function \(\operatorname{clip}_{[0,2]}\) is used to avoid numerical issues.</p>

                <hr style="margin: 2rem 0; border: 1px solid #dbdbdb;" />

                <p>FaceDistance allows to:</p>
                <ul>
                  <li>Rank generated images by similarity (lower distance = better match)</li>
                  <li>Discard the top \(k\%\) of distant embeddings to improve personalization quality (e.g., \(k=15\%\) for datasets with \(n \geq 8\))</li>
                  <li>Identify failure cases such as off-subject images or artifacts</li>
                </ul>

                <p>In our paper, we explore these use cases in detail.</p>
              </div>

              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig21.jpg" width="700" alt="FaceDistance Metric Visualization" class="is-centered" />
                <p class="has-text-centered" style="margin-top: 10px;">
                  <em>Visualization of ranking using the FaceDistance metric for qualitative facial similarity assessment.</em>
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title has-text-centered">InstantID Pipelines</h2>
              <div class="content has-text-justified">
                <p>
                  We analyze two distinct InstantID pipeline approaches for generating personalized portraits, each offering different trade-offs between facial similarity and
                  compositional control.
                </p>

                <h3>2-Step Generation</h3>
                <p>
                  In <strong>2-step generation</strong>, we collect <strong>s</strong>ubject reference images (s<sub>1</sub>, ..., s<sub>n</sub>) and a separate image representing
                  the desired pose and composition s<sub>kpts</sub>. These are used as reference images and the keypoints image, respectively. While the resulting output is
                  generally satisfactory, using facial landmarks from one person to generate another reduces facial similarity due to structural differences in the five keypoints
                  (eyes, nose, mouth). We hypothesize this stems from imbalanced conditioning weights. Performance improves when replacing s<sub>kpts</sub> with a previously
                  generated image of the subject, yielding better facial similarity while maintaining compositional control.
                </p>
                <div class="column is-centered has-text-centered">
                  <img src="static/figures/fig6.jpg" width="700" alt="InstantID Pipelines Comparison" class="is-centered" />
                  <p class="has-text-justified" style="margin-top: 10px;">
                    <em>Two-Step Generation Pipeline. Initial outputs use a keypoints image (s<sub>kpts</sub>) from another identity, often reducing facial similarity. Replacing
                      s<sub>kpts</sub> with a prior output of the subject improves identity preservation while retaining pose. Using four reference images offers a good trade-off,
                      as demonstrated in the appendix. Despite the ease-of-use in downstream applications, this limitation motivates our face replacement method for greater
                      control.</em>
                  </p>
                </div>

                <h3>Face Replacement</h3>
                <p>
                  In <strong>face replacement</strong>, users interact with a simple tool to manipulate (move/rotate/resize) their cropped face on a canvas matching the diffusion
                  model's output dimensions. This approach eliminates the similarity issues caused by using another person's facial landmarks. However, the method performs poorly
                  when none of the reference images show the subject facing the camera (deviations >30Â°). User satisfaction was higher with this approach compared to <em>2-step
                    generation</em>, which we attribute to increased interactivity and faster generation times.
                </p>
              </div>



            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section hero section-contrast">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title has-text-centered">User Study Results</h2>
              <div class="content has-text-justified">
                <p>
                  Our survey evaluated the professional viability of AI-generated portraits, comparing DreamBooth and InstantID headshot generators with <strong>97 white-collar
                    professionals and students</strong>. Participants aged 18-74, mostly aged 45+, assessed quality, facial similarity, and realism.
                </p>
                <h3>Key Findings</h3>
                <ul>
                  <li><strong>Demographics:</strong> Predominantly White (81%) and older adults (74.2% over 45), balanced gender representation.</li>
                  <li><strong>Performance:</strong> DreamBooth and InstantID delivered similar quality and detail; DreamBooth showed superior facial similarity.</li>
                  <li><strong>Preferences:</strong> Slight preference (~4%) for InstantIDâ€™s consistent professional style; DreamBooth favored for realistic identity preservation.
                  </li>
                  <li><strong>AI Detection:</strong> Most participants struggled to identify AI portraits; experienced AI users more often detected DreamBooth images.</li>
                </ul>
                <p>These findings highlight the strengths and user perceptions of AI portrait generators in professional settings.</p>
              </div>
            </div>


            <div id="results-carousel" class="carousel results-carousel">
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig16.jpg" width="600" class="is-centered" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig15.jpg" width="600" class="is-centered" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig14.jpg" width="600" class="is-centered" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig13.jpg" width="600" class="is-centered" />
              </div>
            </div>
          </div>
        </div>
      </div>
      </div>
    </section>

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{Ulusan2025SynData4CV,  
  author        = {Ulusan, Koray and Kiefer, Benjamin},
  title         = {{Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID}},
  booktitle     = {Proceedings of the CVPR 2025 Workshop on Synthetic Data for Computer Vision (SynData4CV)},
  year          = {2025},
  month         = {May},
  url           = {https://openreview.net/forum?id=2o0RxrcV23},
  note          = {Accepted to the CVPR 2025 SynData4CV Workshop},
  eprint        = {2505.03557},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  doi           = {10.48550/arXiv.2505.03557}
}
</code></pre>
      </div>
    </section>

    <footer class="footer">
      <div class="columns is-centered">
        <div class="column is-8 content">
          <p>
            Website template is borrowed from the <a href="https://nerfies.github.io/">Nerfies</a> project and is licensed under <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.
          </p>
        </div>
      </div>
    </footer>


</body>

</html>