<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description"
    content="Research paper on improving facial resemblance in AI-generated portraits using DreamBooth and InstantID through synthetic data augmentation. CVPR 2025 SynData4CV Workshop.">
  <meta name="keywords"
    content="DreamBooth, InstantID, facial resemblance, AI portraits, synthetic data, augmentation, computer vision, CVPR 2025, text-to-image generation, personalization">
  <meta name="author" content="Koray Ulusan, Benjamin Kiefer">
  <meta name="robots" content="index, follow">
  <link rel="canonical" href="https://synthetic-face-augmentation.github.io/">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="website">
  <meta property="og:title" content="Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID" />
  <meta property="og:description"
    content="Research paper on improving facial resemblance in AI-generated portraits using DreamBooth and InstantID through synthetic data augmentation. CVPR 2025 SynData4CV Workshop.">
  <meta property="og:url" content="https://synthetic-face-augmentation.github.io/" />
  <meta property="og:image" content="https://synthetic-face-augmentation.github.io/static/figures/fig1.jpg" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />
  <meta property="og:site_name" content="Synthetic Face Augmentation Research">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID">
  <meta name="twitter:description"
    content="Research paper on improving facial resemblance in AI-generated portraits using DreamBooth and InstantID through synthetic data augmentation. CVPR 2025 SynData4CV Workshop.">
  <meta name="twitter:image" content="https://synthetic-face-augmentation.github.io/static/figures/fig1.jpg">

  <!-- LinkedIn optimized Open Graph tags -->
  <meta property="og:image:alt"
    content="Pipeline overview showing synthetic face augmentation process using DreamBooth and InstantID for improved facial resemblance in AI-generated portraits">
  <meta property="og:locale" content="en_US">
  <meta property="article:author" content="https://www.linkedin.com/in/korayulusan/">
  <meta property="article:published_time" content="2025-05-01T00:00:00Z">
  <meta property="article:modified_time" content="2025-07-01T00:00:00Z">
  <meta property="article:section" content="Computer Vision">
  <meta property="article:tag" content="DreamBooth">
  <meta property="article:tag" content="InstantID">
  <meta property="article:tag" content="Facial Resemblance">
  <meta property="article:tag" content="AI Portraits">
  <meta property="article:tag" content="Synthetic Data">
  <meta property="article:tag" content="CVPR 2025">


  <title>Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID</title>


  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-YD6FV17NYE"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-YD6FV17NYE');
  </script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- Favicons -->
  <link rel="apple-touch-icon" sizes="57x57" href="static/favicon/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="static/favicon/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="static/favicon/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="static/favicon/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="static/favicon/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="static/favicon/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="static/favicon/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="static/favicon/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="static/favicon/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="static/favicon/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="static/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="static/favicon/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/favicon/favicon-16x16.png">
  <link rel="manifest" href="static/favicon/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="static/favicon/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true
      },
      TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js"]
      }
    });
  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML'></script>

  <!-- Structured Data / JSON-LD -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID",
    "description": "Research paper on improving facial resemblance in AI-generated portraits using DreamBooth and InstantID through synthetic data augmentation techniques.",
    "image": "https://synthetic-face-augmentation.github.io/static/figures/fig1.jpg",
    "url": "https://synthetic-face-augmentation.github.io/",
    "datePublished": "2025-05-01",
    "dateModified": "2025-07-01",
    "author": [
      {
        "@type": "Person",
        "name": "Koray Ulusan",
        "url": "https://www.linkedin.com/in/korayulusan/",
        "affiliation": {
          "@type": "Organization",
          "name": "University of Tuebingen"
        }
      },
      {
        "@type": "Person",
        "name": "Benjamin Kiefer",
        "url": "https://scholar.google.com/citations?user=IgH9QkEAAAAJ",
        "affiliation": [
          {
            "@type": "Organization",
            "name": "University of Tuebingen"
          },
          {
            "@type": "Organization",
            "name": "LOOKOUT"
          }
        ]
      }
    ],
    "publisher": {
      "@type": "Organization",
      "name": "CVPR 2025 SynData4CV Workshop"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Computer Vision"
      },
      {
        "@type": "Thing",
        "name": "Artificial Intelligence"
      },
      {
        "@type": "Thing",
        "name": "Machine Learning"
      },
      {
        "@type": "Thing",
        "name": "Image Generation"
      }
    ],
    "keywords": "DreamBooth, InstantID, facial resemblance, AI portraits, synthetic data, augmentation, computer vision, CVPR 2025",
    "citation": {
      "@type": "CreativeWork",
      "name": "arXiv:2505.03557",
      "url": "https://arxiv.org/abs/2505.03557"
    },
    "isPartOf": {
      "@type": "Event",
      "name": "CVPR 2025 SynData4CV Workshop",
      "url": "https://syndata4cv.github.io/"
    }
  }
  </script>
</head>

<body>

  <header>
    <section class="publication-header">
      <div class="hero-body">
        <div class="container is-max-widescreen">
          <!-- <div class="columns is-centered"> -->
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID</h1>
          </div>
        </div>
      </div>
    </section>
  </header>

  <main>





    <section class="publication-author-block">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <div class="is-size-4 publication-authors">
                <span class="author-block"><a href="https://www.linkedin.com/in/korayulusan/" target="_blank">Koray Ulusan</a><sup>1</sup>,</span>
                <span class="author-block"><a href="https://scholar.google.com/citations?user=IgH9QkEAAAAJ" target="_blank">Benjamin Kiefer</a><sup>1,2</sup></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>University of Tuebingen</span>
                <span class="author-block"><sup>2</sup>LOOKOUT</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2505.03557" target="_blank" class="external-link button is-normal is-rounded">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2505.03557" target="_blank" class="external-link button is-normal is-rounded">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="#" target="_blank" class="external-link button is-normal is-rounded">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code (Coming Soon)</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/KorayUlusan/fsxl-dataset" target="_blank" class="external-link button is-normal is-rounded">
                      <span class="icon">
                        <i class="fas fa-database"></i>
                      </span>
                      <span>FSXL Dataset</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/KorayUlusan/fpxl-dataset" target="_blank" class="external-link button is-normal is-rounded">
                      <span class="icon">
                        <i class="fas fa-database"></i>
                      </span>
                      <span>FPXL Dataset</span>
                    </a>
                  </span>


                </div>
              </div>


              <div class="is-size-5 publication-authors">
                <span class="author-block">Accepted to <a href="https://syndata4cv.github.io/" target="_blank">SynData4CV <!-- Workshop -->@ CVPR 2025</a></span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero is-small">
      <section class="hero teaser">
        <div class="container is-max-desktop">
          <div class="hero-body">
            <div class="container">
              <div class="item">
                <img src="static/figures/fig1.jpg" width="100%"
                  alt="Pipeline overview showing synthetic face augmentation process using DreamBooth and InstantID for improved facial resemblance in AI-generated portraits" />
                <h2 class="content has-text-justified">
                  <br>
                  Pipeline for generating personalized portraits using synthetic images enhanced through classical and generative augmentations to improve identity resemblance in
                  DreamBooth and InstantID outputs. We compare classical augmentations with generative augmentation using InstantID's synthetic images to enrich training data.
                </h2>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section class="section hero section-contrast">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="item">
                </p>
              </div>
              <h2 class="title is-3">Abstract</h2>
              <article class="content has-text-justified">
                <p>
                  Personalizing Stable Diffusion for professional portrait generation from amateur photos faces challenges in maintaining facial resemblance. This paper evaluates
                  the
                  impact of augmentation strategies on two personalization methods: DreamBooth and InstantID.
                </p>
                <p>
                  We compare classical augmentations (flipping, cropping, color adjustments) with generative augmentation using InstantID's synthetic images to enrich training
                  data.
                  Using SDXL and a new FaceDistance metric based on FaceNet, we quantitatively assess facial similarity.
                </p>
                <p>
                  Results show classical augmentations can cause artifacts harming identity retention, while InstantID improves fidelity when balanced with real images to avoid
                  overfitting. A user study with 97 participants confirms high photorealism and preferences for InstantID's polished look versus DreamBooth's identity accuracy.
                </p>
                <p>
                  Our findings inform effective augmentation strategies for personalized text-to-image generation.
                </p>
              </article>
            </div>
          </div>
        </div>
      </section>

      <section class="hero is-small">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title has-text-centered">Augmentation Strategy Results</h2>
                <div class="content has-text-justified">
                  <p>
                    We evaluate augmentation strategies on <strong>DreamBooth</strong> and <strong>InstantID</strong> personalization methods using the SDXL model and a new
                    <em>FaceDistance</em> metric to measure facial similarity.
                  </p>
                  <h3>Key Findings</h3>
                  <ul>
                    <li><strong>Classical Augmentations (DreamBooth):</strong> Often introduce artifacts harming identity retention. Techniques like random flips and background
                      replacements can slow training or degrade image quality. Gray backgrounds (especially light gray) work best. Resizing images to ~1MP aligns well with SDXL
                      training, while ESR-GAN upscaling introduces artifacts.</li>
                    <li><strong>Generative Augmentations (InstantID):</strong> Enhance DreamBooth training by producing diverse, realistic synthetic images that improve facial
                      similarity. Maintaining a balance between real and synthetic images is critical to avoid overfitting. Though effective, the 2-step generation method is
                      computationally costly.</li>
                    <li><strong>InstantID’s Behavior:</strong> Rotational/shape augmentations and background replacements degrade similarity. Upscaling with traditional methods
                      works
                      better than neural upscaling. Using multiple reference images significantly improves consistency. Face replacement offers better pose control and faster
                      generation, but requires well-posed reference photos.</li>
                  </ul>
                  <h3>Overall Insights</h3>
                  <ul>
                    <li>DreamBooth excels in facial similarity, while InstantID yields a more professional, "Photoshopped" look favored by some users.</li>
                    <li>FaceDistance effectively ranks facial similarity but has limited sensitivity for fine distinctions and holistic personalization.</li>
                    <li>Datasets with very few images \((\leq 3)\) can result in poor subject representation despite seeming accurate to outsiders.</li>
                  </ul>
                </div>
              </div>
            </div>

            <div id="results-carousel" class="carousel results-carousel">
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig2.jpg" width="750"
                  alt="Classical augmentations analysis showing flipping, cropping, and color adjustments effects on DreamBooth facial similarity" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig3.jpg" width="600" alt="Generative augmentations using InstantID synthetic images to enhance DreamBooth training data quality" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig4-ab.jpg" width="600"
                  alt="Comparison between DreamBooth and InstantID methods for personalized portrait generation showing facial similarity metrics" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig4-cd.jpg" width="600" alt="Additional DreamBooth vs InstantID comparison results demonstrating identity preservation differences" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig10.jpg" width="600" alt="InstantID pipeline results showing professional portrait generation with enhanced facial resemblance" />
              </div>
            </div>
          </div>
        </div>
      </section>

      <section class="section hero section-contrast">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title has-text-centered">FaceDistance Metric</h2>
                <div class="content has-text-justified">
                  <p>
                    To quantify facial similarity in generated images, we employ the <strong>FaceDistance</strong> metric based on FaceNet embeddings [Schroff et al., 2015].
                    FaceNet projects facial images into a
                    128-dimensional hyperspherical embedding space where spatial proximity reflects facial similarity.
                  </p>

                  <p>
                    <strong>Definition:</strong> Given batches of generated images \( G = \{G_i\}_{i=1}^m \) and real images \( R = \{R_j\}_{j=1}^n \), the FaceDistance is defined
                    as:
                  </p>

                  <div class="has-text-centered" style="margin: 20px 0;">
                    \[
                    \bigl[\operatorname{FaceDistance}(G, R)\bigr]_i := \frac{1}{n} \sum_{j=1}^n \delta^{[0,2]}_{\cos}\bigl(f(G_i), f(R_j)\bigr), \quad i=1, \dots, m
                    \]
                  </div>

                  <p>where</p>

                  <ul>
                    <li>\( f(\cdot) := \operatorname{FaceNet}\bigl(\operatorname{MTCNN}(\cdot)\bigr) \)</li>
                    <li>\(\delta^{[0,2]}_{\cos}(\mathbf{x}, \mathbf{y}) := \operatorname{clip}_{[0,2]} \left( 1 - \frac{\mathbf{x}^\top \mathbf{y}}{\|\mathbf{x}\| \,
                      \|\mathbf{y}\|}
                      \right)\)</li>

                  </ul>

                  <p>The clipping function \(\operatorname{clip}_{[0,2]}\) is used to avoid numerical issues.</p>

                  <hr style="margin: 2rem 0; border: 1px solid #dbdbdb;" />

                  <p>FaceDistance allows to:</p>
                  <ul>
                    <li>Rank generated images by similarity (lower distance = better match)</li>
                    <li>Discard the top \(k\%\) of distant embeddings to improve personalization quality (e.g., \(k=15\%\) for datasets with \(n \geq 8\))</li>
                    <li>Identify failure cases such as off-subject images or artifacts</li>
                  </ul>

                  <p>In our paper, we explore these use cases in detail.</p>
                </div>

                <div class="column is-centered has-text-centered">
                  <img src="static/figures/fig21.jpg" width="700"
                    alt="FaceDistance metric visualization demonstrating ranking system for qualitative facial similarity assessment using FaceNet embeddings"
                    class="is-centered" />
                  <p class="has-text-centered" style="margin-top: 10px;">
                    <em>Visualization of ranking using the FaceDistance metric for qualitative facial similarity assessment.</em>
                  </p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section class="section hero">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title has-text-centered">InstantID Pipelines</h2>
                <div class="content has-text-justified">
                  <p>
                    We analyze two distinct InstantID pipeline approaches for generating personalized portraits, each offering different trade-offs between facial similarity and
                    compositional control.
                  </p>

                  <h3>2-Step Generation</h3>
                  <p>
                    We collect <strong>s</strong>ubject reference images (s<sub>1</sub>, ..., s<sub>n</sub>) and a separate image
                    representing
                    the desired pose and composition s<sub>kpts</sub>. These are used as reference images and the keypoints image, respectively. While the resulting output is
                    generally satisfactory, using facial landmarks from one person to generate another reduces facial similarity due to structural differences in the five keypoints
                    (eyes, nose, mouth). We hypothesize this stems from imbalanced conditioning weights. Performance improves when replacing s<sub>kpts</sub> with a previously
                    generated image of the subject, yielding better facial similarity while maintaining compositional control.
                  </p>
                  <div class="column is-centered has-text-centered">
                    <img src="static/figures/fig6.jpg"
                      alt="InstantID two-step generation pipeline comparison showing keypoints-based versus subject-based reference image approaches for improved facial similarity"
                      class="is-centered" />
                    <p class="has-text-justified" style="margin-top: 10px;">
                      <em>Two-Step Generation Pipeline. Initial outputs use a keypoints image (s<sub>kpts</sub>) from another identity, often reducing facial similarity. Replacing
                        s<sub>kpts</sub> with a prior output of the subject improves identity preservation while retaining pose. Using four reference images offers a good
                        trade-off,
                        as demonstrated in the appendix. Despite the ease-of-use in downstream applications, this limitation motivates our face replacement method for greater
                        control.</em>
                    </p>
                  </div>

                  <h3>Face Replacement</h3>
                  <p>
                    Users interact with a simple tool to manipulate (move/rotate/resize) their cropped face on a canvas matching the diffusion
                    model's output dimensions. This approach eliminates the similarity issues caused by using another person's facial landmarks. However, the method performs poorly
                    when none of the reference images show the subject facing the camera (deviations >30°). User satisfaction was higher with this approach compared to <em>2-step
                      generation</em>, which we attribute to increased interactivity and faster generation times.
                  </p>
                </div>



              </div>
            </div>
          </div>
        </div>
      </section>

      <section class="section hero section-contrast">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title has-text-centered">User Study Results</h2>
                <div class="content has-text-justified">
                  <p>
                    Our survey evaluated the professional viability of AI-generated portraits, comparing DreamBooth and InstantID headshot generators with <strong>97 white-collar
                      professionals and students</strong>. Participants aged 18-74 assessed quality, facial similarity, and realism.
                  </p>
                  <h3>Key Findings</h3>
                  <ul>
                    <li><strong>Demographics:</strong> Predominantly White (81%) and older adults (74.2% over 45), balanced gender representation.</li>
                    <li><strong>Performance:</strong> DreamBooth and InstantID delivered similar quality and detail; DreamBooth showed superior facial similarity.</li>
                    <li><strong>Preferences:</strong> Slight preference (\(\Delta=4\%\)) for InstantID’s consistent professional style; DreamBooth favored for realistic identity
                      preservation.
                    </li>
                    <li><strong>AI Detection:</strong> Most participants struggled to identify AI portraits; experienced AI users more often detected DreamBooth images.</li>
                  </ul>
                  <p>These findings highlight the strengths and user perceptions of AI portrait generators in professional settings.</p>
                </div>
              </div>
            </div>
            <div id="results-carousel-2" class="carousel results-carousel">
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig16.jpg" width="750" alt="User study demographics breakdown showing age distribution and professional background of 97 participants"
                  class="is-centered" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig15.jpg" width="750" alt="User study quality assessment comparing DreamBooth vs InstantID for professional portrait generation"
                  class="is-centered" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig14.jpg" width="750"
                  alt="Facial similarity ratings from user study showing DreamBooth performance versus InstantID in identity preservation" class="is-centered" />
              </div>
              <div class="column is-centered has-text-centered">
                <img src="static/figures/fig13.jpg" width="700" alt="AI detection accuracy results from user study evaluating ability to identify AI-generated portraits"
                  class="is-centered" />
              </div>
            </div>
          </div>
        </div>
        </div>
      </section>
      <section class="section hero" aria-label="FSXL and FPXL Portrait Datasets">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title has-text-centered">
                  Flickr-Suits-XL & Flickr-Portraits-XL Datasets
                </h2>
                <div class="buttons is-centered" style="margin-top: 1.5rem;">
                  <span class="link-block">
                    <a href="https://github.com/KorayUlusan/fsxl-dataset" target="_blank" class="external-link button is-normal is-rounded">
                      <span class="icon">
                        <i class="fas fa-database"></i>
                      </span>
                      <span>FSXL Dataset</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/KorayUlusan/fpxl-dataset" target="_blank" class="external-link button is-normal is-rounded">
                      <span class="icon">
                        <i class="fas fa-database"></i>
                      </span>
                      <span>FPXL Dataset</span>
                    </a>
                  </span>
                </div>

                <div class="content has-text-justified">
                  <p>
                    We introduce <strong>Flickr-Suits-XL (FSXL)</strong> and <strong>Flickr-Portraits-XL (FPXL)</strong>, two high-quality datasets for AI-generated professional
                    portraits.
                  </p>

                  <p>
                    <strong>FSXL</strong> includes 1,208 high-resolution images of people in formal attire, sourced from Flickr under permissive licenses. Images were filtered
                    using MTCNN (single face), aligned, and cropped to match SDXL training resolution, with faces centered horizontally and positioned one-third from the top.
                  </p>

                  <p>
                    <strong>FPXL</strong> follows the same process using raw, in-the-wild FFHQ images.
                    Both datasets inherit demographic biases.
                  </p>


                  <div id="results-carousel-2" class="carousel results-carousel">
                    <div class="column is-centered has-text-centered">
                      <img src="static/figures/fig18.jpg" width="400" alt="Samples from FSXL dataset showing people in formal attire" class="is-centered" />
                    </div>
                    <div class="column is-centered has-text-centered">
                      <img src="static/figures/fig19.jpg" width="400" alt="Samples from FPXL dataset based on FFHQ in-the-wild portraits" class="is-centered" />
                    </div>
                  </div>


                </div>
              </div>
            </div>
          </div>
        </div>
      </section>


      <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title">BibTeX</h2>
          <pre><code>@inproceedings{Ulusan2025SynData4CV,  
  author        = {Ulusan, Koray and Kiefer, Benjamin},
  title         = {{Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID}},
  booktitle     = {Proceedings of the CVPR 2025 Workshop on Synthetic Data for Computer Vision (SynData4CV)},
  year          = {2025},
  month         = {May},
  url           = {https://openreview.net/forum?id=2o0RxrcV23},
  note          = {Accepted to the CVPR 2025 SynData4CV Workshop},
  eprint        = {2505.03557},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  doi           = {10.48550/arXiv.2505.03557}
}
</code></pre>
        </div>
      </section>

  </main>

  <footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8 content">
        <p>
          Website template is borrowed from the <a href="https://nerfies.github.io/">Nerfies</a> project and is licensed under <a rel="license"
            href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.
        </p>
      </div>
    </div>
  </footer>


</body>

</html>